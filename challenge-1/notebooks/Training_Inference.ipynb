{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d7aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sayantan\\anaconda3\\envs\\pt\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total images: 1222\n",
      "           image_id      soil_type\n",
      "0  img_ed005410.jpg  Alluvial soil\n",
      "1  img_0c5ecd2a.jpg  Alluvial soil\n",
      "2  img_ed713bb5.jpg  Alluvial soil\n",
      "3  img_12c58874.jpg  Alluvial soil\n",
      "4  img_eff357af.jpg  Alluvial soil\n",
      "\n",
      "Class distribution:\n",
      "       soil_type  count\n",
      "0  Alluvial soil    528\n",
      "1       Red soil    264\n",
      "2     Black Soil    231\n",
      "3      Clay soil    199\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 0. Imports & Environment Setup\n",
    "# ============================================\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from torchvision import transforms, models\n",
    "import timm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ============================================\n",
    "# 1. Constants & Paths\n",
    "# ============================================\n",
    "# Imagenet normalization stats\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Mapping soil-type names â†’ integer labels\n",
    "label_map = {\n",
    "    'Alluvial soil': 0,\n",
    "    'Black Soil'   : 1,\n",
    "    'Clay soil'    : 2,\n",
    "    'Red soil'     : 3\n",
    "}\n",
    "inv_label_map = {v:k for k,v in label_map.items()}\n",
    "\n",
    "# Filepaths for train metadata and image directories\n",
    "TRAIN_CSV = 'soil_classification-2025/train_labels.csv'\n",
    "TRAIN_DIR = 'soil_classification-2025/train'\n",
    "TEST_DIR  = 'soil_classification-2025/test'\n",
    "\n",
    "# ============================================\n",
    "# 2. Read & Inspect CSV Labels\n",
    "# ============================================\n",
    "df = pd.read_csv(TRAIN_CSV)\n",
    "print(\"Total images:\", len(df))\n",
    "print(df.head())\n",
    "\n",
    "# Show class distribution\n",
    "dist = df['soil_type'].value_counts().rename_axis('soil_type').reset_index(name='count')\n",
    "print(\"\\nClass distribution:\")\n",
    "print(dist)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03848bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.21 | packaged by conda-forge | (main, Dec  5 2024, 13:41:22) [MSC v.1929 64 bit (AMD64)]\n",
      "Torch version: 2.6.0+cu118 CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "# Print versions for debugging\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"Torch version:\", torch.__version__, \"CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978cea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3. Data Transforms\n",
    "# ============================================\n",
    "# Augmentations + normalization for training\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Only resizing + normalization for validation\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6a8c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 4. Custom Dataset Definition\n",
    "# ============================================\n",
    "class SoilDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for loading soil images and labels.\n",
    "    Expects a DataFrame with columns ['image_id', 'soil_type'].\n",
    "    \"\"\"\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # Load image and convert to RGB\n",
    "        img = Image.open(f\"{self.img_dir}/{row['image_id']}\").convert('RGB')\n",
    "        # Apply transforms if provided\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        # Map soil-type string â†’ integer label\n",
    "        label = label_map[row['soil_type']]\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b651b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 977, Val size: 245\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 5. Train/Validation Split & Sampling\n",
    "# ============================================\n",
    "# Stratified split to preserve class ratios\n",
    "train_df, val_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['soil_type'],\n",
    "    random_state=42\n",
    ")\n",
    "print(f\"Train size: {len(train_df)}, Val size: {len(val_df)}\")\n",
    "\n",
    "# Instantiate datasets\n",
    "train_dataset = SoilDataset(train_df, TRAIN_DIR, transform=train_transform)\n",
    "val_dataset   = SoilDataset(val_df,   TRAIN_DIR, transform=val_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8e263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([0.5788, 1.3203, 1.5362, 1.1576], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute balanced class weights for FocalLoss\n",
    "train_targets = train_df['soil_type'].map(label_map).values\n",
    "classes       = np.unique(train_targets)\n",
    "cw            = compute_class_weight('balanced', classes=classes, y=train_targets)\n",
    "class_weights = torch.tensor(cw, dtype=torch.float).to(device)\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804d0d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up WeightedRandomSampler to correct for imbalance in DataLoader\n",
    "class_sample_counts = np.bincount(train_targets)\n",
    "weights             = 1.0 / class_sample_counts\n",
    "samples_weight      = weights[train_targets]\n",
    "samples_weight      = torch.from_numpy(samples_weight).double()\n",
    "\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=samples_weight,\n",
    "    num_samples=len(samples_weight),\n",
    "    replacement=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e120bf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 6. Loss Function: Focal Loss\n",
    "# ============================================\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements focal loss for multi-class classification.\n",
    "    down-weights well-classified examples (gamma > 0).\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=2.0, weight=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.weight = weight\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        # Compute log-softmax & probabilities\n",
    "        log_softmax = F.log_softmax(input, dim=1)  # [B, C]\n",
    "        probs = torch.exp(log_softmax)             # [B, C]\n",
    "\n",
    "        # Select the log-prob and prob for the true class\n",
    "        logpt = log_softmax.gather(1, target.unsqueeze(1)).squeeze(1)  # [B]\n",
    "        pt    = probs.gather(1, target.unsqueeze(1)).squeeze(1)       # [B]\n",
    "\n",
    "        # Focal loss formula\n",
    "        loss = -((1 - pt) ** self.gamma) * logpt\n",
    "\n",
    "        # Apply per-class weighting if provided\n",
    "        if self.weight is not None:\n",
    "            loss = loss * self.weight[target]\n",
    "\n",
    "        return loss.mean()\n",
    "\n",
    "criterion = FocalLoss(gamma=2.0, weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0ac808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 7. Model Definition: Swin Transformer\n",
    "# ============================================\n",
    "class SwinClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Swin Transformer backbone + simple linear classifier head.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name='swin_tiny_patch4_window7_224', num_classes=4, pretrained=True):\n",
    "        super(SwinClassifier, self).__init__()\n",
    "        # Load pre-trained backbone with no head\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0\n",
    "        )\n",
    "        # Add a new linear layer for our 4 soil classes\n",
    "        self.classifier = nn.Linear(self.backbone.num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)                # [B, backbone_features]\n",
    "        logits   = self.classifier(features)       # [B, num_classes]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b6e780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and move to device\n",
    "model = SwinClassifier(num_classes=4).to(device)\n",
    "print(\"Model:\", model)\n",
    "\n",
    "# ============================================\n",
    "# 8. Optimizer & Scheduler\n",
    "# ============================================\n",
    "# Different LRs for backbone vs. classifier head\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': model.backbone.parameters(), 'lr': 1e-5},\n",
    "    {'params': model.classifier.parameters(), 'lr': 1e-4}\n",
    "], weight_decay=0.01)\n",
    "\n",
    "# Reduce LR on plateau of validation loss\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf358f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,       # from your Step 2\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler,\n",
    "    num_workers=0        # use 0 first to debug; bump to 2â€“4 when stable\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,         # from your Step 2\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ef1b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: SwinClassifier(\n",
      "  (backbone): SwinTransformer(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "      (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (layers): Sequential(\n",
      "      (0): SwinTransformerStage(\n",
      "        (downsample): Identity()\n",
      "        (blocks): Sequential(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): Identity()\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): Identity()\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.009)\n",
      "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.009)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1): SwinTransformerStage(\n",
      "        (downsample): PatchMerging(\n",
      "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.018)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.018)\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.027)\n",
      "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.027)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): SwinTransformerStage(\n",
      "        (downsample): PatchMerging(\n",
      "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.036)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.036)\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.045)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.045)\n",
      "          )\n",
      "          (2): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.055)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.055)\n",
      "          )\n",
      "          (3): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.064)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.064)\n",
      "          )\n",
      "          (4): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.073)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.073)\n",
      "          )\n",
      "          (5): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.082)\n",
      "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.082)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): SwinTransformerStage(\n",
      "        (downsample): PatchMerging(\n",
      "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "          (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "        )\n",
      "        (blocks): Sequential(\n",
      "          (0): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.091)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.091)\n",
      "          )\n",
      "          (1): SwinTransformerBlock(\n",
      "            (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (attn): WindowAttention(\n",
      "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "              (softmax): Softmax(dim=-1)\n",
      "            )\n",
      "            (drop_path1): DropPath(drop_prob=0.100)\n",
      "            (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (mlp): Mlp(\n",
      "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (act): GELU(approximate='none')\n",
      "              (drop1): Dropout(p=0.0, inplace=False)\n",
      "              (norm): Identity()\n",
      "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (drop2): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (drop_path2): DropPath(drop_prob=0.100)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (head): ClassifierHead(\n",
      "      (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "      (drop): Dropout(p=0.0, inplace=False)\n",
      "      (fc): Identity()\n",
      "      (flatten): Identity()\n",
      "    )\n",
      "  )\n",
      "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
      ")\n",
      "Train Loader: torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
      "Val Loader: torch.Size([32, 3, 224, 224]) torch.Size([32])\n",
      "Criterion: FocalLoss()\n",
      "Optimizer: AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 1e-05\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.01\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 9. Sanity-Check Data Loaders\n",
    "# ============================================\n",
    "# Grab one batch from each loader to confirm shapes\n",
    "train_batch = next(iter(train_loader))\n",
    "val_batch   = next(iter(val_loader))\n",
    "print(\"Train Loader:\", train_batch[0].shape, train_batch[1].shape)\n",
    "print(\"Val Loader:  \", val_batch[0].shape,   val_batch[1].shape)\n",
    "print(\"Criterion:\", criterion)\n",
    "print(\"Optimizer:\", optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9fb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:10: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.4546 | Acc: 0.6940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.2163 | Acc: 0.8204 | F1 Score: 0.8161\n",
      "âœ… Best model updated\n",
      "\n",
      "Epoch 2/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.1515 | Acc: 0.9048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.1129 | Acc: 0.8776 | F1 Score: 0.8776\n",
      "âœ… Best model updated\n",
      "\n",
      "Epoch 3/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0929 | Acc: 0.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0793 | Acc: 0.9347 | F1 Score: 0.9355\n",
      "âœ… Best model updated\n",
      "\n",
      "Epoch 4/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0544 | Acc: 0.9509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0592 | Acc: 0.9429 | F1 Score: 0.9437\n",
      "âœ… Best model updated\n",
      "\n",
      "Epoch 5/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0371 | Acc: 0.9570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0583 | Acc: 0.9469 | F1 Score: 0.9473\n",
      "âœ… Best model updated\n",
      "\n",
      "Epoch 6/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0264 | Acc: 0.9734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0418 | Acc: 0.9551 | F1 Score: 0.9556\n",
      "âœ… Best model updated\n",
      "\n",
      "Epoch 7/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:08<00:00,  3.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0217 | Acc: 0.9693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0443 | Acc: 0.9510 | F1 Score: 0.9517\n",
      "\n",
      "Epoch 8/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:08<00:00,  3.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0136 | Acc: 0.9867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0341 | Acc: 0.9551 | F1 Score: 0.9556\n",
      "\n",
      "Epoch 9/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:08<00:00,  3.51batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0215 | Acc: 0.9785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0248 | Acc: 0.9714 | F1 Score: 0.9716\n",
      "âœ… Best model updated\n",
      "\n",
      "Epoch 10/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:08<00:00,  3.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0225 | Acc: 0.9785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.04batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0528 | Acc: 0.9551 | F1 Score: 0.9557\n",
      "\n",
      "Epoch 11/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.40batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0160 | Acc: 0.9836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0247 | Acc: 0.9673 | F1 Score: 0.9675\n",
      "\n",
      "Epoch 12/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:08<00:00,  3.47batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0098 | Acc: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0292 | Acc: 0.9673 | F1 Score: 0.9675\n",
      "\n",
      "Epoch 13/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:08<00:00,  3.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0063 | Acc: 0.9959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0223 | Acc: 0.9796 | F1 Score: 0.9796\n",
      "âœ… Best model updated\n",
      "\n",
      "Epoch 14/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0094 | Acc: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0373 | Acc: 0.9796 | F1 Score: 0.9797\n",
      "\n",
      "Epoch 15/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:08<00:00,  3.46batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0078 | Acc: 0.9939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  5.02batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0218 | Acc: 0.9837 | F1 Score: 0.9837\n",
      "âœ… Best model updated\n",
      "\n",
      "Epoch 16/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.19batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0089 | Acc: 0.9898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0199 | Acc: 0.9755 | F1 Score: 0.9756\n",
      "\n",
      "Epoch 17/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0057 | Acc: 0.9908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.76batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0173 | Acc: 0.9837 | F1 Score: 0.9837\n",
      "\n",
      "Epoch 18/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.43batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0045 | Acc: 0.9969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0198 | Acc: 0.9837 | F1 Score: 0.9838\n",
      "\n",
      "Epoch 19/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.36batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0032 | Acc: 0.9990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0189 | Acc: 0.9755 | F1 Score: 0.9757\n",
      "\n",
      "Epoch 20/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0046 | Acc: 0.9939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0202 | Acc: 0.9878 | F1 Score: 0.9878\n",
      "âœ… Best model updated\n",
      "\n",
      "Epoch 21/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.15batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0046 | Acc: 0.9969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0154 | Acc: 0.9878 | F1 Score: 0.9878\n",
      "\n",
      "Epoch 22/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:09<00:00,  3.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0028 | Acc: 0.9980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.86batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0225 | Acc: 0.9796 | F1 Score: 0.9797\n",
      "\n",
      "Epoch 23/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:08<00:00,  3.45batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0046 | Acc: 0.9949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.90batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0203 | Acc: 0.9796 | F1 Score: 0.9797\n",
      "\n",
      "Epoch 24/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:08<00:00,  3.44batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0032 | Acc: 0.9949\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0186 | Acc: 0.9878 | F1 Score: 0.9878\n",
      "\n",
      "Epoch 25/25\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?batch/s]C:\\Users\\sayantan\\AppData\\Local\\Temp\\ipykernel_32772\\773548765.py:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():  # AMP\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 31/31 [00:08<00:00,  3.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ› ï¸ Train - Loss: 0.0025 | Acc: 0.9969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:01<00:00,  4.98batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Validation - Loss: 0.0201 | Acc: 0.9878 | F1 Score: 0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 10. Training Loop\n",
    "# ============================================\n",
    "num_epochs = 25\n",
    "best_acc   = 0.0\n",
    "scaler     = GradScaler()  # for mixed-precision\n",
    "\n",
    "# Tracking metrics\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()   # enable dropout, etc.\n",
    "            data_loader = train_loader\n",
    "        else:\n",
    "            model.eval()    # disable dropout, etc.\n",
    "            data_loader = val_loader\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        all_preds, all_labels = [], []\n",
    "\n",
    "        # Iterate batches with progress bar\n",
    "        with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "            for inputs, labels in tepoch:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward + backward (only if training)\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    with autocast():  # mixed-precision\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Get predictions\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        # Scale + backward + step for AMP\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                # Accumulate loss & accuracy\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data).item()\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "                # For validation F1 calculation\n",
    "                if phase == 'val':\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        # Compute epoch metrics\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc  = running_corrects / total_samples\n",
    "\n",
    "        if phase == 'train':\n",
    "            train_losses.append(epoch_loss)\n",
    "            train_accuracies.append(epoch_acc)\n",
    "            print(f\"ðŸ› ï¸ Train - Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "        else:\n",
    "            # Validation: compute F1 & adjust LR\n",
    "            epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "            val_losses.append(epoch_loss)\n",
    "            val_accuracies.append(epoch_acc)\n",
    "            lr_scheduler.step(epoch_loss)\n",
    "\n",
    "            print(f\"ðŸ§ª Validation - Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f} | F1 Score: {epoch_f1:.4f}\")\n",
    "\n",
    "            # Save best model weights by accuracy\n",
    "            if epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, 'best_soil_model.pth')\n",
    "                print(\"âœ… Best model updated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80f2f6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 341/341 [00:03<00:00, 90.94it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved predictions to prediction.csv (same order as input CSV)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SwinClassifier(num_classes=4).to(device)\n",
    "\n",
    "# 3. Load your trained weights\n",
    "checkpoint_path = 'best_soil_model.pth'\n",
    "state_dict = torch.load(checkpoint_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Prepare your class labels\n",
    "# -------------------------------\n",
    "class_names = ['Alluvial soil', 'Black Soil', 'Clay soil', 'Red soil']\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Define the image transforms\n",
    "# -------------------------------\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Load your test IDs CSV\n",
    "# -------------------------------\n",
    "test_csv_path = os.path.join('soil_classification-2025', 'test_ids.csv')\n",
    "test_df = pd.read_csv(test_csv_path)  \n",
    "# test_df['image_id'] order is kept as in the file\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Run inference\n",
    "# -------------------------------\n",
    "predictions = []\n",
    "for img_name in tqdm(test_df['image_id'], desc=\"Predicting\"):\n",
    "    img_path = os.path.join('soil_classification-2025', 'test', img_name)\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        inp = test_transforms(img).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(inp)\n",
    "            pred_idx = logits.argmax(dim=1).item()\n",
    "        predictions.append(class_names[pred_idx])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_name}: {e}\")\n",
    "        predictions.append(\"Error\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Attach predictions & save\n",
    "# -------------------------------\n",
    "test_df['soil_type'] = predictions\n",
    "output_path = 'prediction.csv'\n",
    "test_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"âœ… Saved predictions to {output_path} (same order as input CSV)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1417201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
